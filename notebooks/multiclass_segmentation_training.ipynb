{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HW-7gA_WwIf7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from numpy import asarray\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras import layers\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.io import imread, imshow\n",
        "from skimage.transform import resize\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import cv2 as cv2\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! pip install -q kaggle\n",
        "from google.colab import files \n",
        "files.upload()\n",
        "! mkdir ~/.kaggle \n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets list\n",
        "! kaggle datasets download -c 'duckietown_segmentation_example'\n",
        "! mkdir dataset\n",
        "! unzip duckietown_segmentation_example.zip -d dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "QhSfPnELwKeN",
        "outputId": "01943e9b-621f-4541-abdc-cdc96ab6f0fb"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-28fca1a2deb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mORIG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{i}.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mORIG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{i}.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2850\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2852\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# load every image into memory\n",
        "ORIG = 'dataset/images_stable/rgb_orig_rand'\n",
        "TARGET = 'dataset/images_stable/rgb_ss'\n",
        "\n",
        "n = 100\n",
        "TRAIN_DIM = 60\n",
        "IMG_WIDTH = 320\n",
        "IMG_HEIGHT = 240\n",
        "IMG_CHANNELS = 3\n",
        "N_CLASSES = 3  #  central line (yellow), lateral line (white) and not a line\n",
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "for i in range(n):\n",
        "  if os.path.isfile(os.path.join(ORIG, f'{i}.png')):\n",
        "    img = Image.open(os.path.join(ORIG, f'{i}.png'))\n",
        "    data = asarray(img)\n",
        "    x_train.append(data)\n",
        "    img = Image.open(os.path.join(TARGET, f'{i}_seg.png'))\n",
        "    data = asarray(img)\n",
        "    y_train.append(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9kkY7QuqwTHK"
      },
      "outputs": [],
      "source": [
        "x_train = [np.delete(elem, [False, False, False, True], axis=2) for elem in x_train]\n",
        "y_train = [np.delete(elem, [False, False, False, True], axis=2) for elem in y_train]\n",
        "print(len(x_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmGDFeF_wVQp"
      },
      "outputs": [],
      "source": [
        "x_test = x_train[TRAIN_DIM:]\n",
        "x_train = x_train[:TRAIN_DIM]\n",
        "y_test = y_train[TRAIN_DIM:]\n",
        "y_train = y_train[:TRAIN_DIM]\n",
        "\n",
        "#print(x_train[0])\n",
        "x_train = np.array(x_train)\n",
        "x_test = np.array(x_test)\n",
        "y_test = np.array(y_test)\n",
        "y_train = np.array(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m31X0YeDwsAT"
      },
      "outputs": [],
      "source": [
        "def separate_classes(img):\n",
        "  img = np.copy(img)\n",
        "  # remove magenta\n",
        "  img[np.all(img == np.array([255,0,254]), axis=-1)] = np.array([0,0,0])\n",
        "  img_white = np.copy(img)\n",
        "  img_yellow = np.copy(img)\n",
        "  img_no_line = np.copy(img)\n",
        "  # white line\n",
        "  img_white[np.all(img_white == np.array([255,255,0]), axis=-1)] = np.array([0,0,0])\n",
        "  img_white = resize(img_white, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range='true' )\n",
        "  img_white=img_white[:,:,:1]\n",
        "  img_white = np.squeeze(img_white)\n",
        "  img_white = img_white/255.\n",
        "\n",
        "  # yellow line\n",
        "  img_yellow[np.all(img_yellow == np.array([255,255,255]), axis=-1)] = np.array([0,0,0])\n",
        "  img_yellow[np.all(img_yellow == np.array([255,255,0]), axis=-1)] = np.array([255,255,255])\n",
        "  img_yellow = resize(img_yellow, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range='true' )\n",
        "  img_yellow=img_yellow[:,:,:1]\n",
        "  img_yellow = np.squeeze(img_yellow)\n",
        "  img_yellow = img_yellow/255.\n",
        "\n",
        "  # not a line\n",
        "  img_no_line[np.all(img_no_line == np.array([255,255,255]), axis=-1)] = np.array([255,255,0])\n",
        "  img_no_line[np.all(img_no_line == np.array([0,0,0]), axis=-1)] = np.array([255,255,255])\n",
        "  img_no_line[np.all(img_no_line == np.array([255,255,0]), axis=-1)] = np.array([0,0,0])\n",
        "  img_no_line = resize(img_no_line, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range='true' )\n",
        "  img_no_line=img_no_line[:,:,:1]\n",
        "  img_no_line = np.squeeze(img_no_line)\n",
        "  img_no_line = img_no_line/255.\n",
        "\n",
        "  img_masks = np.array([img_white,img_yellow,img_no_line])\n",
        "  return img_masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mswbV--wYIy"
      },
      "outputs": [],
      "source": [
        "LENGTH = y_train.shape[0]\n",
        "\n",
        "Y_train = []\n",
        "\n",
        "for i in range(LENGTH):\n",
        "  img = np.copy(y_train[i])\n",
        "  img = separate_classes(img)\n",
        "  Y_train.append(img)\n",
        "  \n",
        "y_train = np.array(Y_train)\n",
        "print(y_train.shape)\n",
        "#y_train = np.swapaxes(np.swapaxes(y_train, 1, 2), 2, 3)\n",
        "y_train = np.moveaxis(y_train, 1, -1)\n",
        "print(y_train[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYeEVVFoxtWr"
      },
      "outputs": [],
      "source": [
        "LENGTH = y_test.shape[0]\n",
        "\n",
        "Y_test = []\n",
        "\n",
        "for i in range(LENGTH):\n",
        "  img = np.copy(y_test[i])\n",
        "  img = separate_classes(img)\n",
        "  Y_test.append(img)\n",
        "  \n",
        "y_test = np.array(Y_test)\n",
        "#y_test = np.swapaxes(np.swapaxes(y_test, 1, 2), 2, 3)\n",
        "y_test = np.moveaxis(y_test, 1, -1)\n",
        "print(y_test[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3mvXPvM_qma"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2poFlGIT7OpV"
      },
      "source": [
        "If the model isn't sufficiently accurate we can try to enlarge conv2D layers' outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLpgMASmyNnb"
      },
      "outputs": [],
      "source": [
        "inputs = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "s = tf.keras.layers.Lambda(lambda x:x /255)(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvPvvLqYy2Xh"
      },
      "outputs": [],
      "source": [
        "c1 = tf.keras.layers.Conv2D(16, (3,3), activation=\"relu\", kernel_initializer='he_normal', padding='same')(s)\n",
        "c1 = tf.keras.layers.Dropout(0.1)(c1)\n",
        "c1 = tf.keras.layers.Conv2D(16, (3,3), activation=\"relu\", kernel_initializer='he_normal', padding='same')(c1)\n",
        "p1 = tf.keras.layers.MaxPooling2D((2,2))(c1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mta_-TW8y4qL"
      },
      "outputs": [],
      "source": [
        "c2 = tf.keras.layers.Conv2D(32, (3,3), activation=\"relu\", kernel_initializer='he_normal', padding='same')(p1)\n",
        "c2 = tf.keras.layers.Dropout(0.1)(c2)\n",
        "c2 = tf.keras.layers.Conv2D(32, (3,3), activation=\"relu\", kernel_initializer='he_normal', padding='same')(c2)\n",
        "p2 = tf.keras.layers.MaxPooling2D((2,2))(c2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKXoaJnty6ti"
      },
      "outputs": [],
      "source": [
        "c3 = tf.keras.layers.Conv2D(64, (3,3), activation=\"relu\", kernel_initializer='he_normal', padding='same')(p2)\n",
        "c3 = tf.keras.layers.Dropout(0.1)(c3)\n",
        "c3 = tf.keras.layers.Conv2D(64, (3,3), activation=\"relu\", kernel_initializer='he_normal', padding='same')(c3)\n",
        "p3 = tf.keras.layers.MaxPooling2D((2,2))(c3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xNGT55-y8z8"
      },
      "outputs": [],
      "source": [
        "c4 = tf.keras.layers.Conv2D(128, (3,3), activation=\"relu\", kernel_initializer='he_normal', padding='same')(p3)\n",
        "c4 = tf.keras.layers.Dropout(0.1)(c4)\n",
        "c4 = tf.keras.layers.Conv2D(128, (3,3), activation=\"relu\", kernel_initializer='he_normal', padding='same')(c4)\n",
        "p4 = tf.keras.layers.MaxPooling2D((2,2))(c4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WH9v9EgCzAlu"
      },
      "outputs": [],
      "source": [
        "c5 = tf.keras.layers.Conv2D(256, (3,3), activation=\"relu\", kernel_initializer='he_normal', padding='same')(p4)\n",
        "c5 = tf.keras.layers.Dropout(0.1)(c5)\n",
        "c5 = tf.keras.layers.Conv2D(256, (3,3), activation=\"relu\", kernel_initializer='he_normal', padding='same')(c5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ByMg5_QzDTA"
      },
      "outputs": [],
      "source": [
        "u6 = tf.keras.layers.Convolution2DTranspose(128, (2,2), strides=(2,2), padding='same')(c5)\n",
        "u6 = tf.keras.layers.concatenate([u6, c4]) #merge with old layer\n",
        "c6 = tf.keras.layers.Conv2D(128, (3,3), activation=\"relu\", kernel_initializer='he_normal', padding='same')(u6)\n",
        "c6 = tf.keras.layers.Dropout(0.1)(c6)\n",
        "c6 = tf.keras.layers.Conv2D(128, (3,3), activation=\"relu\", kernel_initializer='he_normal', padding='same')(c6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdX8Ob0MzFvM"
      },
      "outputs": [],
      "source": [
        "u7 = tf.keras.layers.Convolution2DTranspose(64, (2,2), strides=(2,2), padding='same')(c6)\n",
        "u7 = tf.keras.layers.concatenate([u7, c3])  #merge with old layer\n",
        "c7 = tf.keras.layers.Conv2D(64, (3,3), activation=\"relu\", kernel_initializer='he_normal', padding='same')(u7)\n",
        "c7 = tf.keras.layers.Dropout(0.1)(c7)\n",
        "c7 = tf.keras.layers.Conv2D(64, (3,3), activation=\"relu\", kernel_initializer='he_normal', padding='same')(c7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KirEAFQEzIHV"
      },
      "outputs": [],
      "source": [
        "u8 = tf.keras.layers.Convolution2DTranspose(32, (2,2), strides=(2,2), padding='same')(c7)\n",
        "u8 = tf.keras.layers.concatenate([u8, c2])  #merge with old layer\n",
        "c8 = tf.keras.layers.Conv2D(32, (3,3), activation=\"relu\", kernel_initializer='he_normal', padding='same')(u8)\n",
        "c8 = tf.keras.layers.Dropout(0.1)(c8)\n",
        "c8 = tf.keras.layers.Conv2D(32, (3,3), activation=\"relu\", kernel_initializer='he_normal', padding='same')(c8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C__Xr0e4zKjD"
      },
      "outputs": [],
      "source": [
        "u9 = tf.keras.layers.Convolution2DTranspose(16, (2,2), strides=(2,2), padding='same')(c8)\n",
        "u9 = tf.keras.layers.concatenate([u9, c1])  #merge with old layer\n",
        "c9 = tf.keras.layers.Conv2D(16, (3,3), activation=\"relu\", kernel_initializer='he_normal', padding='same')(u9)\n",
        "c9 = tf.keras.layers.Dropout(0.1)(c9)\n",
        "c9 = tf.keras.layers.Conv2D(16, (3,3), activation=\"relu\", kernel_initializer='he_normal', padding='same')(c9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kq7rNGnFzMx6"
      },
      "outputs": [],
      "source": [
        "outputs = tf.keras.layers.Conv2D(N_CLASSES, (1,1), activation = 'softmax')(c9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0JOSzOU6hBi"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "model.summary()\n",
        "\n",
        "checkpointer = tf.keras.callbacks.ModelCheckpoint('duckie_street.h5', verbose=1, save_best_only=True)\n",
        "callbacks=[\n",
        "    tf.keras.callbacks.EarlyStopping(patience=100, monitor='val_loss'),\n",
        "    tf.keras.callbacks.TensorBoard(log_dir='logs')]\n",
        "results = model.fit(x_train,y_train, validation_split=0.1, batch_size = BATCH_SIZE, epochs=100, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJfftcZb6nAY"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import matplotlib.pyplot\n",
        "\n",
        "seed = 42\n",
        "np.random.seed = seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0aUFaQrl6s53"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "TEST_LENGTH = x_test.shape[0]\n",
        "print(TEST_LENGTH)\n",
        "idx1 = np.random.randint(0,TEST_LENGTH)\n",
        "idx2 = np.random.randint(0,TEST_LENGTH)\n",
        "\n",
        "# 1\n",
        "imshow(x_test[idx1])\n",
        "plt.show()\n",
        "\n",
        "prediction = model.predict(x_test[idx1].reshape((1,IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)))\n",
        "prediction = np.squeeze(prediction)\n",
        "\n",
        "masks = []\n",
        "max_vals = prediction.max(axis=-1) #take the max value along the probability axis\n",
        "for i in range(N_CLASSES):\n",
        "  masks.append(prediction[:,:,i] == max_vals)\n",
        "  masks[i] = np.array(masks[i], dtype=int)\n",
        "  masks[i] = np.array([masks[i]*255 for _ in range(3)])\n",
        "  masks[i] = np.moveaxis(masks[i], 0, -1)\n",
        "  imshow(masks[i])\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# 2\n",
        "imshow(x_test[idx2])\n",
        "plt.show()\n",
        "\n",
        "prediction = model.predict(x_test[idx2].reshape((1,IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)))\n",
        "prediction = np.squeeze(prediction)\n",
        "\n",
        "masks = []\n",
        "max_vals = prediction.max(axis=-1) #take the max value along the probability axis\n",
        "for i in range(N_CLASSES):\n",
        "  masks.append(prediction[:,:,i] == max_vals)\n",
        "  masks[i] = np.array(masks[i], dtype=int)\n",
        "  masks[i] = np.array([masks[i]*255 for _ in range(3)])\n",
        "  masks[i] = np.moveaxis(masks[i], 0, -1)\n",
        "  imshow(masks[i])\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save('multiclass_segmentation')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
